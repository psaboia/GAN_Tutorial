{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining GAN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><img src=\"./images/GeneralFramework.png\" align-items=\"left\"></th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.core import Activation\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def GAN_Model(noise_shape, image_shape, loss, optimizer_type, metrics):\n",
    "    \n",
    "    # Define noise vector\n",
    "    Z = Input(shape = noise_shape)\n",
    "\n",
    "    # Get generator model\n",
    "    G = Generator(noise_shape)\n",
    "\n",
    "    # Get discriminator model\n",
    "    D = Discriminator(image_shape)\n",
    "\n",
    "    # GAN Model\n",
    "    D.trainable = False\n",
    "    GAN = Model(input = Z, output = D(G(Z)))\n",
    "    GAN.compile(loss = loss, optimizer = optimizer_type, metrics = metrics)\n",
    "    GAN.summary()\n",
    "    \n",
    "    return GAN, G, D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator $G$ Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Kernel initialization notes\n",
    "\n",
    "<code>kernel_initializer = 'glorot_uniform'</code> _(being used)_ \n",
    "\n",
    "- The Glorot uniform initializer, also called Xavier uniform initializer.\n",
    "\n",
    "- It draws samples from a uniform distribution within [-limit, limit] where limit is sqrt(6 / (fan_in + fan_out)) where fan_in is the number of input units in the weight tensor and fan_out is the number of output units in the weight tensor.\n",
    "\n",
    "<code>kernel_initializer = RandomNormal(mean=0.0, stddev=0.01)</code>\n",
    "\n",
    "- Outputs random values from a normal distribution.\n",
    "\n",
    "## First Layer Definition Notes\n",
    "### Padding:\n",
    "- Changing padding = 'same' in the first layer makes a lot fo difference!!!!\n",
    "- But he is using in the first layer <code>padding = \"valid\"</code>\n",
    "\n",
    "## LeakReLU\n",
    "\n",
    "The derivative of the LeayReLU is 1 in the positive part, and is a small fraction in the negative part.\n",
    "\n",
    "Leaky version of a Rectified Linear Unit: It allows a small gradient when the unit is not active: \n",
    "\n",
    "$f(x) = alpha * x$, for $x < 0$\n",
    "\n",
    "$f(x) = x$, for $x >= 0$\n",
    "\n",
    "\n",
    "\n",
    "[Tips](https://www.quora.com/What-are-the-advantages-of-using-Leaky-Rectified-Linear-Units-Leaky-ReLU-over-normal-ReLU-in-deep-learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator(noise_shape):\n",
    "    \n",
    "    \"\"\"\n",
    "    Options\n",
    "    \"\"\"\n",
    "    # Conv2D options\n",
    "    df = \"channels_last\"  # data_format\n",
    "    ki = 'glorot_uniform' # kernel_initializer\n",
    "    \n",
    "    # LeakyReLU option\n",
    "    alpha = 0.2\n",
    "    \n",
    "    # BatchNormalization option\n",
    "    momentum = 0.5\n",
    "    \n",
    "    # Loss Function \n",
    "    loss = 'binary_crossentropy'\n",
    "\n",
    "    # Optimizer option\n",
    "    gen_opt = Adam(lr = 0.00015, beta_1 = 0.5)\n",
    "        \n",
    "    # Metric type \n",
    "    metrics = ['accuracy']    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Input Layer {noise}\n",
    "    \"\"\"    \n",
    "    gen_input = Input(shape = noise_shape)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Layer (1) {Conv2DTranspose - BatchNormalization - LeakyReLU}\n",
    "    \"\"\"\n",
    "    f = 512     # amount of filters    \n",
    "    k = (4,4)   # kernel_size\n",
    "    s = (1,1)   # strides    \n",
    "    p = \"valid\" # padding\n",
    "    \n",
    "    generator = Conv2DTranspose(filters = f, kernel_size = k, strides = s, padding = p, data_format = df, kernel_initializer = ki)(gen_input)\n",
    "    generator = BatchNormalization(momentum = momentum)(generator)\n",
    "    generator = LeakyReLU(alpha=alpha)(generator)\n",
    "      \n",
    "        \n",
    "    \"\"\"\n",
    "    Layer (2) {Conv2DTranspose - BatchNormalization - LeakyReLU}\n",
    "    \"\"\"\n",
    "    f = 256    # amount of filters    \n",
    "    k = (4,4)  # kernel_size\n",
    "    s = (2,2)  # strides    \n",
    "    p = \"same\" # padding\n",
    "    \n",
    "    generator = Conv2DTranspose(filters = f, kernel_size = k, strides = s, padding = p, data_format = df, kernel_initializer = ki)(generator)\n",
    "    generator = BatchNormalization(momentum = momentum)(generator)    \n",
    "    generator = LeakyReLU(alpha=alpha)(generator)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Layer (3) {Conv2DTranspose - BatchNormalization - LeakyReLU}\n",
    "    \"\"\"\n",
    "    f = 128 # amount of filters    \n",
    "    \n",
    "    generator = Conv2DTranspose(filters = f, kernel_size = k, strides = s, padding = p, data_format = df, kernel_initializer = ki)(generator)\n",
    "    generator = BatchNormalization(momentum = momentum)(generator)    \n",
    "    generator = LeakyReLU(alpha=alpha)(generator)    \n",
    "\n",
    "    \"\"\"\n",
    "    Layer (4) {Conv2DTranspose - BatchNormalization - LeakyReLU}\n",
    "    \"\"\"\n",
    "    f = 64 # amount of filters    \n",
    "    \n",
    "    generator = Conv2DTranspose(filters = f, kernel_size = k, strides = s, padding = p, data_format = df, kernel_initializer = ki)(generator)\n",
    "    generator = BatchNormalization(momentum = momentum)(generator)    \n",
    "    generator = LeakyReLU(alpha=alpha)(generator)    \n",
    "    \n",
    "    \"\"\"\n",
    "    Layer (5) {Conv2DTranspose - BatchNormalization - LeakyReLU}\n",
    "    \"\"\"    \n",
    "    f = 32 # amount of filters\n",
    "\n",
    "    generator = Conv2DTranspose(filters = f, kernel_size = k, strides = s, padding = p, data_format = df, kernel_initializer = ki)(generator)\n",
    "    generator = BatchNormalization(momentum = momentum)(generator)    \n",
    "    generator = LeakyReLU(alpha=alpha)(generator)    \n",
    "    \n",
    "    \"\"\"\n",
    "    Layer (6) {Conv2DTranspose - BatchNormalization - LeakyReLU}\n",
    "    \"\"\"\n",
    "    f = 16 # amount of filters\n",
    "\n",
    "    generator = Conv2DTranspose(filters = f, kernel_size = k, strides = s, padding = p, data_format = df, kernel_initializer = ki)(generator)\n",
    "    generator = BatchNormalization(momentum = momentum)(generator)\n",
    "    generator = LeakyReLU(alpha=alpha)(generator)\n",
    "        \n",
    "    \"\"\"\n",
    "    Layer (7) {Conv2D - BatchNormalization - LeakyReLU}\n",
    "    \"\"\"    \n",
    "    f = 16    # amount of filters\n",
    "    k = (3,3) # kernel_size\n",
    "    s = (1,1) # strides\n",
    "\n",
    "    generator = Conv2D(filters = f, kernel_size = k, strides = s, padding = p, data_format = df, kernel_initializer = ki)(generator)\n",
    "    generator = BatchNormalization(momentum = momentum)(generator)\n",
    "    generator = LeakyReLU(alpha=alpha)(generator)\n",
    "     \n",
    "    \"\"\"\n",
    "    Layer (8) {Conv2DTranspose - Activation}\n",
    "    \"\"\"\n",
    "    f = 3     # amount of filters\n",
    "    k = (4,4) # kernel_size\n",
    "    s = (2,2) # strides\n",
    "    \n",
    "    generator = Conv2DTranspose(filters = f, kernel_size = k, strides = s, padding = p, data_format = df, kernel_initializer = ki)(generator)\n",
    "    generator = Activation('tanh')(generator)\n",
    "        \n",
    "    \"\"\"\n",
    "    Model\n",
    "    \"\"\"   \n",
    "    generator_model = Model(input = gen_input, output = generator)\n",
    "    generator_model.compile(loss = loss, optimizer = gen_opt, metrics = metrics)\n",
    "    generator_model.summary()\n",
    "\n",
    "    return generator_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator $D$ Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator(image_shape):   \n",
    "    \n",
    "    \"\"\"\n",
    "    Options\n",
    "    \"\"\"\n",
    "    # Conv2D options\n",
    "    k = (4,4)             # kernel_size\n",
    "    s = (2,2)             # strides\n",
    "    p = \"same\"            # padding\n",
    "    df = \"channels_last\"  # data_format\n",
    "    ki = 'glorot_uniform' # kernel_initializer\n",
    "    \n",
    "    # LeakyReLU option\n",
    "    alpha = 0.2\n",
    "    \n",
    "    # BatchNormalization option\n",
    "    momentum = 0.5\n",
    "    \n",
    "    # Loss Function \n",
    "    loss = 'binary_crossentropy'\n",
    "\n",
    "    # Optimizer option\n",
    "    dis_opt = Adam(lr = 0.0002, beta_1 = 0.5)\n",
    "    \n",
    "    # Metric type \n",
    "    metrics = ['accuracy']    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Input Layer \n",
    "    \"\"\"\n",
    "    dis_input = Input(shape = image_shape)\n",
    "        \n",
    "    \"\"\"\n",
    "    Layer (1) {Conv2D - LeakyReLU}\n",
    "    \"\"\"\n",
    "    f = 64 # amount of filters\n",
    "    discriminator = Conv2D(filters = f, kernel_size = k , strides = s, padding = p, data_format = df, kernel_initializer = ki)(dis_input)\n",
    "    discriminator = LeakyReLU(alpha = alpha)(discriminator)\n",
    "    \n",
    "    \"\"\"\n",
    "    Layer (2) {Conv2D - BatchNormalization- LeakyReLU}\n",
    "    \"\"\"    \n",
    "    f = 128 # amount of filters\n",
    "    discriminator = Conv2D(filters = f, kernel_size = k , strides = s, padding = p, data_format = df, kernel_initializer = ki)(discriminator)\n",
    "    discriminator = BatchNormalization(momentum = momentum)(discriminator)\n",
    "    discriminator = LeakyReLU(alpha = alpha)(discriminator)\n",
    "\n",
    "    \"\"\"\n",
    "    Layer (3) {Conv2D - BatchNormalization- LeakyReLU}\n",
    "    \"\"\"\n",
    "    f = 256 # amount of filters\n",
    "    discriminator = Conv2D(filters = f, kernel_size = k , strides = s, padding = p, data_format = df, kernel_initializer = ki)(discriminator)\n",
    "    discriminator = BatchNormalization(momentum = momentum)(discriminator)\n",
    "    discriminator = LeakyReLU(alpha = alpha)(discriminator)\n",
    "    \n",
    "    \"\"\"\n",
    "    Layer (4) {Conv2D - BatchNormalization- LeakyReLU}\n",
    "    \"\"\"\n",
    "    f = 512 # amount of filters\n",
    "    discriminator = Conv2D(filters = f, kernel_size = k , strides = s, padding = p, data_format = df, kernel_initializer = ki)(discriminator)\n",
    "    discriminator = BatchNormalization(momentum = momentum)(discriminator)\n",
    "    discriminator = LeakyReLU(alpha = alpha)(discriminator)\n",
    "\n",
    "    \"\"\"\n",
    "    Layer (5) {Flatten}\n",
    "    \"\"\"        \n",
    "    discriminator = Flatten()(discriminator)\n",
    "    \n",
    "    \"\"\"\n",
    "    Layer (6) {Dense - Activation}\n",
    "    \"\"\"  \n",
    "    discriminator = Dense(1)(discriminator)\n",
    "    discriminator = Activation('sigmoid')(discriminator)\n",
    "    \n",
    "    \"\"\"\n",
    "    Model\n",
    "    \"\"\"      \n",
    "    discriminator_model = Model(input = dis_input, output = discriminator)\n",
    "    discriminator_model.compile(loss = loss, optimizer = dis_opt, metrics = metrics)\n",
    "    discriminator_model.summary()\n",
    "    \n",
    "    return discriminator_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
